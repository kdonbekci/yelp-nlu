{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages import *\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.data.experimental import AUTOTUNE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score, r2_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-alpha0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-7\n",
    "fp = 'float32'\n",
    "tf.config.gpu.set_per_process_memory_growth(True)\n",
    "tf.config.gpu.set_per_process_memory_fraction(.2)\n",
    "tf.keras.backend.set_floatx(fp)\n",
    "tf.keras.backend.set_epsilon(epsilon)\n",
    "tf.keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "glove_dim = 50\n",
    "input_shape = (300, glove_dim, 1)\n",
    "max_length = 300\n",
    "shuffle_buffer_size = batch_size*4\n",
    "prefetch_buffer_size = 1\n",
    "random_seed = np.random.randint(0, 100)\n",
    "test_ratio = 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_sample(dictionary, n_sample=None, random_seed=42):\n",
    "    lens = [len(l) for l in dictionary.values()]\n",
    "    assert min(lens) == max(lens)\n",
    "    n_data = lens[0]\n",
    "    processed = {}\n",
    "    for key, array in dictionary.items():\n",
    "        if n_sample is not None:\n",
    "            processed[key] = shuffle(array, random_state=random_seed)[:n_sample]\n",
    "        else:\n",
    "            processed[key] = shuffle(array, random_state=random_seed)[:n_sample]\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = shuffle_sample(load_data({'review': ['text', 'stars']})['review'],\n",
    "                             random_seed=random_seed\n",
    "                            )\n",
    "x_train, x_test, y_train, y_test = train_test_split(data['text'],\n",
    "                                                    data['stars'],\n",
    "                                                    test_size = test_ratio,\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_lookup = load_pickle(os.path.join(GLOVE_DIR, 'glove-{}D.pkl'.format(glove_dim)))\n",
    "unk_key = '<UNK>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_vector = np.mean(np.array(list(glove_lookup.values())), axis=0)\n",
    "glove_lookup[unk_key] = unk_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "4479553 train sequences\n",
      "2206347 test sequences\n",
      "Average train sequence length: 602\n",
      "Average test sequence length: 602\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "# (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train_tf = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "y_train_tf = tf.data.Dataset.from_tensor_slices(y_train - 1) # to make stars 0-indexed\n",
    "\n",
    "x_test_tf = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "y_test_tf = tf.data.Dataset.from_tensor_slices(y_test - 1)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print('Average train sequence length: {}'.format(\n",
    "    np.mean(list(map(len, x_train)), dtype=int)))\n",
    "print('Average test sequence length: {}'.format(\n",
    "    np.mean(list(map(len, x_test)), dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_token(t):\n",
    "    t = t.lower()\n",
    "    m = re.match('^[^\\w\\'](\\w+).*', t)\n",
    "    if m is not None:\n",
    "        return m.group(1)\n",
    "    else:\n",
    "        return t\n",
    "\n",
    "def tokenize(s):\n",
    "    tokens = []\n",
    "    for t in word_tokenize(s):\n",
    "        tokens.append(clean_token(t))\n",
    "    return tokens\n",
    "\n",
    "# Returns an np.array of glove embeddings for each\n",
    "# word in the given string of shape (word_count, glove_dims)\n",
    "def get_glove_embeddings(tokens):\n",
    "    embeddings = []\n",
    "    \n",
    "    for i, word in enumerate(tokens):\n",
    "#         if i > \n",
    "        if word in glove_lookup:\n",
    "            embeddings.append(glove_lookup[word])\n",
    "        else:\n",
    "            embeddings.append(np.zeros(glove_dim))\n",
    "            \n",
    "#     return(np.array(embeddings, dtype=np.float16))\n",
    "    return(np.array(embeddings, dtype=np.float32))\n",
    "\n",
    "def test_embed(arr):\n",
    "    return get_glove_embeddings(tokenize(arr))\n",
    "\n",
    "def embed(tensor):\n",
    "    return get_glove_embeddings(tokenize(str(tensor.numpy())))\n",
    "\n",
    "@tf.function\n",
    "def fix_dimensions(tensor):\n",
    "    return tf.image.resize_image_with_crop_or_pad(tf.expand_dims(tensor, axis=-1), 300, glove_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_embed = tf.data.Dataset.map(x_train_tf,  lambda review: tf.py_function( embed, [review], tf.float32 ), num_parallel_calls=AUTOTUNE) \n",
    "test_dataset_embed = tf.data.Dataset.map(x_test_tf,  lambda review: tf.py_function( embed, [review], tf.float32 ),num_parallel_calls=AUTOTUNE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_embed = tf.data.Dataset.map(train_dataset_embed, fix_dimensions, num_parallel_calls=AUTOTUNE) \n",
    "test_dataset_embed = tf.data.Dataset.map(test_dataset_embed, fix_dimensions, num_parallel_calls=AUTOTUNE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.zip((train_dataset_embed, y_train_tf))\n",
    "test_dataset = tf.data.Dataset.zip((test_dataset_embed, y_test_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.shuffle(train_dataset, buffer_size=shuffle_buffer_size)\n",
    "test_dataset = tf.data.Dataset.shuffle(test_dataset, buffer_size=shuffle_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.batch(train_dataset, batch_size=batch_size)\n",
    "test_dataset = tf.data.Dataset.batch(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.prefetch(train_dataset, buffer_size=prefetch_buffer_size)\n",
    "test_dataset = tf.data.Dataset.prefetch(test_dataset, buffer_size=prefetch_buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step #1: \n",
    "(# of obsv, # of words, # of glove dims, ...)\n",
    "(16, 300, 50, 1)\n",
    "Access an observation:\n",
    "X[3].numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get data from tensor\n",
    "X = []\n",
    "Y = []\n",
    "for x_batch, y_batch in train_dataset.take(10000 // batch_size):\n",
    "    X.append(x_batch)\n",
    "    Y.append(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_train_tyler(X):\n",
    "    data = np.dstack([X[0].numpy()[i] for i in range(X[0].shape[0])])\n",
    "    for j in range(10000 // batch_size):\n",
    "        if j == 0:\n",
    "            continue\n",
    "        data = np.append(data, np.dstack([X[j].numpy()[i] for i in range(X[j].shape[0])]), axis = 2)\n",
    "    print(\"Shape:\", data.shape)\n",
    "    return(data)\n",
    "\n",
    "def prep_test_tyler(Y):\n",
    "    data = np.concatenate([Y[i].numpy() for i in range(len(Y))])\n",
    "    print(\"Shape:\", data.shape)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (300, 50, 10000)\n"
     ]
    }
   ],
   "source": [
    "x_train_mdl = prep_train_tyler(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mdl = x_train_mdl.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1, 1, 10000)\n"
     ]
    }
   ],
   "source": [
    "y_train_mdl = prep_train_tyler(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mdl = y_train_mdl.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mdl = y_train_mdl.reshape(y_train_mdl.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_mdl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 50, 300)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_mdl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_mdl = x_train_mdl\n",
    "y_test_mdl = y_train_mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 50, 300)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_mdl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_mdl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 2s 268us/sample - loss: 1.5222 - accuracy: 0.4235 - val_loss: 1.3532 - val_accuracy: 0.4380\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 2s 236us/sample - loss: 1.1440 - accuracy: 0.5414 - val_loss: 1.2974 - val_accuracy: 0.4705\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 2s 232us/sample - loss: 0.9163 - accuracy: 0.6417 - val_loss: 1.3209 - val_accuracy: 0.4730\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 0.7248 - accuracy: 0.7232 - val_loss: 1.3134 - val_accuracy: 0.4650\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 2s 230us/sample - loss: 0.5652 - accuracy: 0.8001 - val_loss: 1.5967 - val_accuracy: 0.4880\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 2s 230us/sample - loss: 0.4072 - accuracy: 0.8691 - val_loss: 1.6544 - val_accuracy: 0.4835\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 2s 230us/sample - loss: 0.3038 - accuracy: 0.9103 - val_loss: 1.6751 - val_accuracy: 0.4245\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 2s 231us/sample - loss: 0.2180 - accuracy: 0.9435 - val_loss: 1.8547 - val_accuracy: 0.4840\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 2s 229us/sample - loss: 0.1517 - accuracy: 0.9653 - val_loss: 1.7615 - val_accuracy: 0.4445\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 2s 231us/sample - loss: 0.1059 - accuracy: 0.9796 - val_loss: 1.9703 - val_accuracy: 0.4720\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 2s 230us/sample - loss: 0.0803 - accuracy: 0.9845 - val_loss: 2.0417 - val_accuracy: 0.4590\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 2s 231us/sample - loss: 0.0563 - accuracy: 0.9887 - val_loss: 2.2714 - val_accuracy: 0.4670\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 2s 235us/sample - loss: 0.0434 - accuracy: 0.9908 - val_loss: 2.3489 - val_accuracy: 0.4625\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 0.0364 - accuracy: 0.9910 - val_loss: 2.5427 - val_accuracy: 0.4675\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 0.0448 - accuracy: 0.9874 - val_loss: 2.5910 - val_accuracy: 0.4710\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 2s 232us/sample - loss: 0.0195 - accuracy: 0.9958 - val_loss: 2.6579 - val_accuracy: 0.4600\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 0.0210 - accuracy: 0.9954 - val_loss: 2.8283 - val_accuracy: 0.4640\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 2s 232us/sample - loss: 0.0232 - accuracy: 0.9929 - val_loss: 2.9083 - val_accuracy: 0.4620\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 0.0120 - accuracy: 0.9974 - val_loss: 3.0069 - val_accuracy: 0.4540\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 2s 232us/sample - loss: 0.0133 - accuracy: 0.9956 - val_loss: 2.9866 - val_accuracy: 0.4505\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 2s 232us/sample - loss: 0.0106 - accuracy: 0.9970 - val_loss: 3.1807 - val_accuracy: 0.4570\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 0.0128 - accuracy: 0.9949 - val_loss: 3.2898 - val_accuracy: 0.4610\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 0.0077 - accuracy: 0.9977 - val_loss: 3.3381 - val_accuracy: 0.4500\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 0.0101 - accuracy: 0.9977 - val_loss: 3.4473 - val_accuracy: 0.4650\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 2s 231us/sample - loss: 0.0043 - accuracy: 0.9987 - val_loss: 3.5566 - val_accuracy: 0.4645\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 2s 231us/sample - loss: 0.0088 - accuracy: 0.9974 - val_loss: 3.6829 - val_accuracy: 0.4605\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 0.0054 - accuracy: 0.9980 - val_loss: 3.6869 - val_accuracy: 0.4555\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 2s 232us/sample - loss: 0.0064 - accuracy: 0.9981 - val_loss: 3.8873 - val_accuracy: 0.4645\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 2s 231us/sample - loss: 2.2382e-04 - accuracy: 1.0000 - val_loss: 4.0703 - val_accuracy: 0.4730\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 2s 229us/sample - loss: 0.0059 - accuracy: 0.9981 - val_loss: 3.9313 - val_accuracy: 0.4655\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 2s 235us/sample - loss: 0.0101 - accuracy: 0.9964 - val_loss: 3.9732 - val_accuracy: 0.4670\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 2s 236us/sample - loss: 6.7051e-04 - accuracy: 0.9999 - val_loss: 5.5336 - val_accuracy: 0.4775\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 2s 237us/sample - loss: 0.0011 - accuracy: 0.9996 - val_loss: 4.2215 - val_accuracy: 0.4615\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 0.0153 - accuracy: 0.9971 - val_loss: 4.3390 - val_accuracy: 0.4595\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 0.0118 - accuracy: 0.9971 - val_loss: 4.3702 - val_accuracy: 0.4335\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 2s 231us/sample - loss: 1.8717e-04 - accuracy: 1.0000 - val_loss: 4.3852 - val_accuracy: 0.4660\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 0.0143 - accuracy: 0.9969 - val_loss: 4.4548 - val_accuracy: 0.4740\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 3.9364e-05 - accuracy: 1.0000 - val_loss: 4.5318 - val_accuracy: 0.4635\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 0.0067 - accuracy: 0.9983 - val_loss: 4.4528 - val_accuracy: 0.4595\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 0.0116 - accuracy: 0.9965 - val_loss: 4.5245 - val_accuracy: 0.4415\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 2s 232us/sample - loss: 3.8390e-05 - accuracy: 1.0000 - val_loss: 4.6453 - val_accuracy: 0.4605\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 0.0016 - accuracy: 0.9992 - val_loss: 4.8199 - val_accuracy: 0.4590\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 2s 232us/sample - loss: 2.5680e-05 - accuracy: 1.0000 - val_loss: 4.8388 - val_accuracy: 0.4590\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 2s 232us/sample - loss: 0.0060 - accuracy: 0.9987 - val_loss: 4.8165 - val_accuracy: 0.4585\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 1.1550e-05 - accuracy: 1.0000 - val_loss: 5.0015 - val_accuracy: 0.4615\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 2s 230us/sample - loss: 0.0065 - accuracy: 0.9977 - val_loss: 4.9499 - val_accuracy: 0.4600\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 2s 231us/sample - loss: 1.2945e-05 - accuracy: 1.0000 - val_loss: 7.0594 - val_accuracy: 0.4580\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 2s 231us/sample - loss: 0.0114 - accuracy: 0.9977 - val_loss: 4.9367 - val_accuracy: 0.4565\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 2s 238us/sample - loss: 0.0034 - accuracy: 0.9987 - val_loss: 5.2021 - val_accuracy: 0.4470\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 0.0027 - accuracy: 0.9994 - val_loss: 5.1691 - val_accuracy: 0.4625\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 1.9108e-05 - accuracy: 1.0000 - val_loss: 7.5182 - val_accuracy: 0.4545\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 0.0033 - accuracy: 0.9991 - val_loss: 5.2189 - val_accuracy: 0.4590\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 2s 235us/sample - loss: 0.0027 - accuracy: 0.9994 - val_loss: 5.2385 - val_accuracy: 0.4505\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 2s 232us/sample - loss: 9.3062e-06 - accuracy: 1.0000 - val_loss: 5.4196 - val_accuracy: 0.4530\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 2s 235us/sample - loss: 0.0024 - accuracy: 0.9992 - val_loss: 5.5051 - val_accuracy: 0.4530\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 1.2310e-04 - accuracy: 1.0000 - val_loss: 5.5181 - val_accuracy: 0.4570\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 0.0024 - accuracy: 0.9992 - val_loss: 5.4909 - val_accuracy: 0.4460\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 2s 236us/sample - loss: 1.3917e-05 - accuracy: 1.0000 - val_loss: 5.5548 - val_accuracy: 0.4550\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 0.0156 - accuracy: 0.9969 - val_loss: 5.8209 - val_accuracy: 0.4375\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 2.8728e-04 - accuracy: 0.9999 - val_loss: 5.7198 - val_accuracy: 0.4535\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 2.8296e-06 - accuracy: 1.0000 - val_loss: 5.7806 - val_accuracy: 0.4585\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 3.5471e-04 - accuracy: 0.9998 - val_loss: 5.7263 - val_accuracy: 0.4480\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 1.0122e-06 - accuracy: 1.0000 - val_loss: 5.9065 - val_accuracy: 0.4600\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 2s 231us/sample - loss: 0.0047 - accuracy: 0.9987 - val_loss: 5.8325 - val_accuracy: 0.4605\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 2.6331e-06 - accuracy: 1.0000 - val_loss: 5.8391 - val_accuracy: 0.4580\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 4.1489e-07 - accuracy: 1.0000 - val_loss: 6.0850 - val_accuracy: 0.4550\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 2s 236us/sample - loss: 0.0078 - accuracy: 0.9986 - val_loss: 6.3660 - val_accuracy: 0.4565\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 2s 230us/sample - loss: 8.7766e-06 - accuracy: 1.0000 - val_loss: 6.3121 - val_accuracy: 0.4590\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 2s 232us/sample - loss: 4.3939e-07 - accuracy: 1.0000 - val_loss: 6.2738 - val_accuracy: 0.4565\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 1.3773e-07 - accuracy: 1.0000 - val_loss: 6.4514 - val_accuracy: 0.4505\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 7.6592e-08 - accuracy: 1.0000 - val_loss: 6.5543 - val_accuracy: 0.4550\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 4.7639e-08 - accuracy: 1.0000 - val_loss: 6.6216 - val_accuracy: 0.4580\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 3.6374e-08 - accuracy: 1.0000 - val_loss: 6.6888 - val_accuracy: 0.4580\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 2.9504e-08 - accuracy: 1.0000 - val_loss: 6.7334 - val_accuracy: 0.4550\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 2.3991e-08 - accuracy: 1.0000 - val_loss: 6.7756 - val_accuracy: 0.4560\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 2.0623e-08 - accuracy: 1.0000 - val_loss: 6.8218 - val_accuracy: 0.4550\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 1.8716e-08 - accuracy: 1.0000 - val_loss: 6.8673 - val_accuracy: 0.4580\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 1.7107e-08 - accuracy: 1.0000 - val_loss: 6.9346 - val_accuracy: 0.4605\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 2s 228us/sample - loss: 1.5631e-08 - accuracy: 1.0000 - val_loss: 6.9238 - val_accuracy: 0.4570\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 2s 231us/sample - loss: 1.4395e-08 - accuracy: 1.0000 - val_loss: 6.9763 - val_accuracy: 0.4570\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 1.4395e-08 - accuracy: 1.0000 - val_loss: 7.0072 - val_accuracy: 0.4585\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 2s 231us/sample - loss: 1.3947e-08 - accuracy: 1.0000 - val_loss: 7.0398 - val_accuracy: 0.4590\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 1.2726e-08 - accuracy: 1.0000 - val_loss: 7.0909 - val_accuracy: 0.4595\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 2s 235us/sample - loss: 1.2547e-08 - accuracy: 1.0000 - val_loss: 7.0938 - val_accuracy: 0.4605\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 2s 236us/sample - loss: 1.1578e-08 - accuracy: 1.0000 - val_loss: 7.1059 - val_accuracy: 0.4575\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 2s 235us/sample - loss: 1.1846e-08 - accuracy: 1.0000 - val_loss: 7.1710 - val_accuracy: 0.4600\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 2s 236us/sample - loss: 1.0490e-08 - accuracy: 1.0000 - val_loss: 7.1815 - val_accuracy: 0.4590\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 2s 232us/sample - loss: 1.2964e-08 - accuracy: 1.0000 - val_loss: 7.2633 - val_accuracy: 0.4590\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 2s 230us/sample - loss: 9.2983e-09 - accuracy: 1.0000 - val_loss: 7.2910 - val_accuracy: 0.4600\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 2s 230us/sample - loss: 9.4175e-09 - accuracy: 1.0000 - val_loss: 7.2710 - val_accuracy: 0.4610\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 2s 230us/sample - loss: 8.6874e-09 - accuracy: 1.0000 - val_loss: 7.3428 - val_accuracy: 0.4610\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 8.0317e-09 - accuracy: 1.0000 - val_loss: 7.3218 - val_accuracy: 0.4570\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 2s 237us/sample - loss: 7.5251e-09 - accuracy: 1.0000 - val_loss: 7.3756 - val_accuracy: 0.4590\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 2s 235us/sample - loss: 7.7486e-09 - accuracy: 1.0000 - val_loss: 7.4051 - val_accuracy: 0.4565\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 2s 237us/sample - loss: 8.0615e-09 - accuracy: 1.0000 - val_loss: 7.4283 - val_accuracy: 0.4575\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 2s 236us/sample - loss: 7.7933e-09 - accuracy: 1.0000 - val_loss: 7.4396 - val_accuracy: 0.4575\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 2s 235us/sample - loss: 8.3894e-09 - accuracy: 1.0000 - val_loss: 7.4608 - val_accuracy: 0.4595\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 7.7486e-09 - accuracy: 1.0000 - val_loss: 7.4878 - val_accuracy: 0.4590\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 2s 236us/sample - loss: 7.9870e-09 - accuracy: 1.0000 - val_loss: 7.5163 - val_accuracy: 0.4590\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 2s 236us/sample - loss: 8.7470e-09 - accuracy: 1.0000 - val_loss: 7.5645 - val_accuracy: 0.4610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f45b7d424e0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Build model...')\n",
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu', input_shape=(15000,)))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train_mdl, y_train_mdl,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          validation_split=.2,\n",
    "#           validation_data=(x_test_mdl, y_test_mdl)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 15000)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsamples, nx, ny = x_train_mdl.shape\n",
    "x_softmax = x_train_mdl.reshape((nsamples,nx*ny))\n",
    "x_softmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsamples, nx = y_train_mdl.shape\n",
    "y_softmax = y_train_mdl.reshape((nsamples,))\n",
    "y_softmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_softmax[:8000]\n",
    "y_train = y_softmax[:8000]\n",
    "\n",
    "x_test = x_softmax[8000:]\n",
    "y_test = y_softmax[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaan/anaconda3/envs/yelp-nlu_3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/kaan/anaconda3/envs/yelp-nlu_3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(x_train, y_train)\n",
    "score = classifier.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.412\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yelp-nlu_3.6",
   "language": "python",
   "name": "yelp-nlu_3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
