{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages import *\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.data.experimental import AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-7\n",
    "fp = 'float32'\n",
    "tf.config.gpu.set_per_process_memory_growth(True)\n",
    "tf.config.gpu.set_per_process_memory_fraction(.05)\n",
    "tf.keras.backend.set_floatx(fp)\n",
    "tf.keras.backend.set_epsilon(epsilon)\n",
    "tf.keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_ix = True\n",
    "if to_ix:\n",
    "    all_key_to_ix = load_pickle(os.path.join(GLOVE_DIR, 'glove-byte-float32_to_ix.pkl'))\n",
    "    j = [2]\n",
    "    keys_to_ix = {}\n",
    "    keys_to_ix[NULL_KEY.encode()] = 0\n",
    "    keys_to_ix[UNK_KEY.encode()] = 1 \n",
    "#ASSUMING ix 0 is for NULL and 1 for UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helperfunctions to make your feature definition more readable\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[*value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[*value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(review, to_ix):\n",
    "    \"\"\"\n",
    "    Creates a tf.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "    # Create a dictionary mapping the feature name to the tf.Example-compatible\n",
    "    # data type.\n",
    "    \n",
    "    \n",
    "    \n",
    "    feature = {\n",
    "      'review': _int64_feature(review) if to_ix else _bytes_feature(review),\n",
    "    }\n",
    "\n",
    "    # Create a Features message using tf.train.Example.\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_count = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_ix(review):\n",
    "    ix = []\n",
    "    for word in review:\n",
    "        if word in keys_to_ix:\n",
    "            ix.append(keys_to_ix[word])\n",
    "        else:\n",
    "            keys_to_ix[word] = j[0]\n",
    "            ix.append(j[0])\n",
    "            j[0]+=1\n",
    "    return ix   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _serialize(review, to_ix=False):\n",
    "    if to_ix:\n",
    "        review = _to_ix(review)\n",
    "    return serialize_example(review, to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_paths = [os.path.join(DATASET_DIR, 'preprocessed', 'npy', 'review-text-{:02d}.npy'.format(i)) for i in range(chunk_count)] #100 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n\\xc2\\x02\\n\\xbf\\x02\\n\\x06review\\x12\\xb4\\x02\\x1a\\xb1\\x02\\n\\xae\\x02\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\x0b\\x0c\\r\\x0e\\x0f\\x10\\x07\\x11\\x12\\x13\\x03\\x14\\x07\\x15\\x16\\x17\\x18\\x19\\x1a\\x1b\\x1c\\x18\\x1d\\x1e\\x1f !\"#\\x03$%&\\x07\\'\\x10(\\t)!\\x17\\x04*\\t\\x12\\x03\\x07+,-.\\x03/&\\x07012\\x173*\\x0345\\x176\\r7\\x1789\\x075\\t!\\x17\\x18:;\\x03\\x0e<4*=\\x10\\x18>\\x1e?\\x034@A\\x17#9\\r\\rBC\\tDE\\x07F\\x034G\\x1b5\\tH-IJ\\x03/K5\\tLMNO$P\\x178Q/\\x17RS!\\rTU!V$WXY\"\\x07#Z[\\\\Y]!^\\x03/_`ab\"cdef\\tghY]\\x18i\\tjk=\\x03\\x18il\\x03\\x04f\\x03\\x07mnopq\\r\\r\\r\\x0erstu\\x03v!\\x18w\\x03cdxyz\\x07\\x0c\\x03\\x18{\\x1e|\\x1b\\x13}\\x1b\\n*H\\t~[\\x7f\\x80\\x01\\r\\x81\\x01\\x10!\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_serialize(review[12], to_ix=to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': <tf.Tensor: id=4, shape=(300,), dtype=int64, numpy=\n",
       " array([  2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "         15,  16,   7,  17,  18,  19,   3,  20,   7,  21,  22,  23,  24,\n",
       "         25,  26,  27,  28,  24,  29,  30,  31,  32,  33,  34,  35,   3,\n",
       "         36,  37,  38,   7,  39,  16,  40,   9,  41,  33,  23,   4,  42,\n",
       "          9,  18,   3,   7,  43,  44,  45,  46,   3,  47,  38,   7,  48,\n",
       "         49,  50,  23,  51,  42,   3,  52,  53,  23,  54,  13,  55,  23,\n",
       "         56,  57,   7,  53,   9,  33,  23,  24,  58,  59,   3,  14,  60,\n",
       "         52,  42,  61,  16,  24,  62,  30,  63,   3,  52,  64,  65,  23,\n",
       "         35,  57,  13,  13,  66,  67,   9,  68,  69,   7,  70,   3,  52,\n",
       "         71,  27,  53,   9,  72,  45,  73,  74,   3,  47,  75,  53,   9,\n",
       "         76,  77,  78,  79,  36,  80,  23,  56,  81,  47,  23,  82,  83,\n",
       "         33,  13,  84,  85,  33,  86,  36,  87,  88,  89,  34,   7,  35,\n",
       "         90,  91,  92,  89,  93,  33,  94,   3,  47,  95,  96,  97,  98,\n",
       "         34,  99, 100, 101, 102,   9, 103, 104,  89,  93,  24, 105,   9,\n",
       "        106, 107,  61,   3,  24, 105, 108,   3,   4, 102,   3,   7, 109,\n",
       "        110, 111, 112, 113,  13,  13,  13,  14, 114, 115, 116, 117,   3,\n",
       "        118,  33,  24, 119,   3,  99, 100, 120, 121, 122,   7,  12,   3,\n",
       "         24, 123,  30, 124,  27,  19, 125,  27,  10,  42,  72,   9, 126,\n",
       "         91, 127, 128,  13, 129,  16,  33,   3,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0])>}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_parse_function(_serialize(review[12], to_ix=to_ix), to_ix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(chunk_count):\n",
    "    chunk = np.load(review_paths[i],allow_pickle=False)\n",
    "    break\n",
    "    chunk_tf = [_serialize(x, to_ix = to_ix) for x in chunk]\n",
    "    chunk_ds = tf.data.Dataset.from_tensor_slices(chunk_tf)\n",
    "    writer_path = os.path.join(DATASET_DIR, 'preprocessed', 'tfrecord', 'ix' if to_ix else 'xext',\n",
    "                               'review-{}-{:02d}.tf'.format('ix' if to_ix else 'text', i))\n",
    "    writer = tf.data.experimental.TFRecordWriter(writer_path)\n",
    "    writer.write(chunk_ds)\n",
    "    print(i+1, end=', ')\n",
    "if to_ix:\n",
    "    save_pickle(os.path.join(GLOVE_DIR, 'glove-byte-keys_to_ix.pkl'), keys_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170431"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keys_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in chunk_ds:break\n",
    "# writer = tf.data.experimental.TFRecordWriter(writer_path)\n",
    "# writer.write(chunk_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(proto, to_ix):\n",
    "    # define your tfrecord again. Remember that you saved your image as a string.\n",
    "    keys_to_features = {'review': tf.io.FixedLenFeature([300,], tf.int64) if to_ix else tf.io.FixedLenFeature([300,], tf.string),}\n",
    "    \n",
    "    # Load one example\n",
    "    parsed_features = tf.io.parse_single_example(proto, keys_to_features)\n",
    "    \n",
    "    return parsed_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset(writer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: _parse_function(x, to_ix)['review'], num_parallel_calls=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dataset:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yelp-nlu_3.6",
   "language": "python",
   "name": "yelp-nlu_3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
